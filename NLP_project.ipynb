{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuTCusXINjErNmtc3+RaGS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnKiTu03/NLP/blob/main/NLP_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlFuA0zHByCt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.schema import HumanMessage\n",
        "import json\n",
        "\n",
        "def extract_elements(url):\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, timeout=5)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        forms_and_actions = []\n",
        "        for form in soup.find_all('form'):\n",
        "            forms_and_actions.append({\n",
        "                \"formHTML\": str(form),\n",
        "                \"actionURL\": form.get(\"action\")\n",
        "            })\n",
        "\n",
        "        links = [a.get('href') for a in soup.find_all('a', href=True)]\n",
        "        scripts = [str(script) for script in soup.find_all('script')]\n",
        "        meta_info = [\"{}={}\".format(m.get('name'), m.get('content')) for m in soup.find_all('meta') if m.get('name')]\n",
        "        title = soup.title.string if soup.title else ''\n",
        "        text_content = soup.get_text()\n",
        "\n",
        "        return {\n",
        "            \"title\": title,\n",
        "            \"text_content\": text_content,\n",
        "            \"forms_and_actions\": forms_and_actions,\n",
        "            \"links\": links,\n",
        "            \"meta_info\": meta_info,\n",
        "            \"scripts\": scripts\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "def llm_content_check(url):\n",
        "    api_key = \"AIyQvk9cOqEQ\"\n",
        "    if not api_key:\n",
        "        raise ValueError(\"GOOGLE_API_KEY environment variable is not set.\")\n",
        "\n",
        "    website_content = extract_elements(url)\n",
        "    if not website_content:\n",
        "        print(\"Failed to extract website content.\")\n",
        "        return\n",
        "\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", api_key=api_key)\n",
        "\n",
        "    message = HumanMessage(\n",
        "        content=(\n",
        "            \"You are acting as a Website Validator. \"\n",
        "            \"You are acting as a Website Validator. Your task is to analyze the content of the provided website and determine whether it is legitimate or a scam.\\n\\n\"\n",
        "            '''Instructions:\n",
        "               1. Carefully review the website content provided below, including its title, text content, links, forms, meta information, and scripts.\n",
        "               2. Evaluate the legitimacy of the website based on these factors:\n",
        "                  - Professional appearance and structure.\n",
        "                  - Informative and relevant content.'''\n",
        "            '''Provide the output strictly in JSON format with the following structure:\n",
        "                {\n",
        "                    Result: <Scam or Legitimate>,\n",
        "                    Reasons: [\n",
        "                        Reason 1,\n",
        "                        Reason 2,\n",
        "                        Reason 3,\n",
        "                        Reason 4,\n",
        "                        Reason 5\n",
        "                      ],\n",
        "                    Conclusion: <A one-liner conclusion summarizing your evaluation>\n",
        "                }'''\n",
        "\n",
        "            f\"Website Content:\\n{website_content}\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    response = llm.invoke([message])\n",
        "    response = response.content\n",
        "    print(response)\n",
        "\n",
        "    if response.startswith(\"```json\"):\n",
        "        response = response[7:]\n",
        "    if response.endswith(\"```\"):\n",
        "        response = response[:-3]\n",
        "    parsed = json.loads(response)\n",
        "    parsed = json.dumps(parsed, indent=4)\n",
        "    return parsed\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "website = \"https://www.msrit.edu\"\n",
        "llm_output = llm_content_check(website)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f2Z1ilwCluL",
        "outputId": "1f9ba7af-b15c-4d9b-989b-6f34457ca7b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"Result\": \"Legitimate\",\n",
            "  \"Reasons\": [\n",
            "    \"Professional website design and structure.\",\n",
            "    \"Informative and relevant content related to the institution.\",\n",
            "    \"Presence of contact information and social media links.\",\n",
            "    \"Valid meta information and scripts.\",\n",
            "    \"No red flags or suspicious elements found.\"\n",
            "  ],\n",
            "  \"Conclusion\": \"Based on the provided content, the website appears legitimate and represents Ramaiah Institute of Technology.\"\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "By7WmtJ_B1S3",
        "outputId": "10ffc5f1-f121-461d-d09c-92189019695d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"Result\": \"Legitimate\",\n",
            "    \"Reasons\": [\n",
            "        \"Professional website design and structure.\",\n",
            "        \"Informative and relevant content related to the institution.\",\n",
            "        \"Presence of contact information and social media links.\",\n",
            "        \"Valid meta information and scripts.\",\n",
            "        \"No red flags or suspicious elements found.\"\n",
            "    ],\n",
            "    \"Conclusion\": \"Based on the provided content, the website appears legitimate and represents Ramaiah Institute of Technology.\"\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}
